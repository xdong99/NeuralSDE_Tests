{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Sequence\n",
    "\n",
    "import fire\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import torchsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1, iters)\n",
    "        self._val = maxval / self._iters\n",
    "        self._maxval = maxval\n",
    "\n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val + self._maxval / self._iters)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticLorenz(object):\n",
    "\n",
    "    noise_type = \"diagonal\"\n",
    "    sde_type = \"ito\"\n",
    "\n",
    "    def __init__(self, a: Sequence = (10., 28., 8 / 3), b: Sequence = (.1, .28, .3)):\n",
    "        super(StochasticLorenz, self).__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def f(self, t, y):\n",
    "        x1, x2, x3 = torch.split(y, split_size_or_sections=(1, 1, 1), dim=1)\n",
    "        a1, a2, a3 = self.a\n",
    "\n",
    "        f1 = a1 * (x2 - x1)\n",
    "        f2 = a2 * x1 - x2 - x1 * x3\n",
    "        f3 = x1 * x2 - a3 * x3\n",
    "        return torch.cat([f1, f2, f3], dim=1)\n",
    "\n",
    "    def g(self, t, y):\n",
    "        x1, x2, x3 = torch.split(y, split_size_or_sections=(1, 1, 1), dim=1)\n",
    "        b1, b2, b3 = self.b\n",
    "\n",
    "        g1 = x1 * b1\n",
    "        g2 = x2 * b2\n",
    "        g3 = x3 * b3\n",
    "        return torch.cat([g1, g2, g3], dim=1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, x0, ts, noise_std, normalize):\n",
    "        \"\"\"Sample data for training. Store data normalization constants if necessary.\"\"\"\n",
    "        xs = torchsde.sdeint(self, x0, ts)\n",
    "        if normalize:\n",
    "            mean, std = torch.mean(xs, dim=(0, 1)), torch.std(xs, dim=(0, 1))\n",
    "            xs.sub_(mean).div_(std).add_(torch.randn_like(xs) * noise_std)\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out, _ = self.gru(inp)\n",
    "        out = self.lin(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(nn.Module):\n",
    "    sde_type = \"ito\"\n",
    "    noise_type = \"diagonal\"\n",
    "\n",
    "    def __init__(self, data_size, latent_size, context_size, hidden_size):\n",
    "        super(LatentSDE, self).__init__()\n",
    "        # Encoder.\n",
    "        self.encoder = Encoder(input_size=data_size, hidden_size=hidden_size, output_size=context_size)\n",
    "        self.qz0_net = nn.Linear(context_size, latent_size + latent_size)\n",
    "\n",
    "        # Decoder.\n",
    "        self.f_net = nn.Sequential(\n",
    "            nn.Linear(latent_size + context_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "        self.h_net = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "        # This needs to be an element-wise function for the SDE to satisfy diagonal noise.\n",
    "        self.g_nets = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(1, hidden_size),\n",
    "                    nn.Softplus(),\n",
    "                    nn.Linear(hidden_size, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "                for _ in range(latent_size)\n",
    "            ]\n",
    "        )\n",
    "        self.projector = nn.Linear(latent_size, data_size)\n",
    "\n",
    "        self.pz0_mean = nn.Parameter(torch.zeros(1, latent_size))\n",
    "        self.pz0_logstd = nn.Parameter(torch.zeros(1, latent_size))\n",
    "\n",
    "        self._ctx = None\n",
    "\n",
    "    def contextualize(self, ctx):\n",
    "        self._ctx = ctx  # A tuple of tensors of sizes (T,), (T, batch_size, d).\n",
    "\n",
    "    def f(self, t, y):\n",
    "        ts, ctx = self._ctx\n",
    "        i = min(torch.searchsorted(ts, t, right=True), len(ts) - 1)\n",
    "        return self.f_net(torch.cat((y, ctx[i]), dim=1))\n",
    "\n",
    "    def h(self, t, y):\n",
    "        return self.h_net(y)\n",
    "\n",
    "    def g(self, t, y):  # Diagonal diffusion.\n",
    "        y = torch.split(y, split_size_or_sections=1, dim=1)\n",
    "        out = [g_net_i(y_i) for (g_net_i, y_i) in zip(self.g_nets, y)]\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "    def forward(self, xs, ts, noise_std, adjoint=False, method=\"euler\"):\n",
    "        # Contextualization is only needed for posterior inference.\n",
    "        ctx = self.encoder(torch.flip(xs, dims=(0,)))\n",
    "        ctx = torch.flip(ctx, dims=(0,))\n",
    "        self.contextualize((ts, ctx))\n",
    "\n",
    "        qz0_mean, qz0_logstd = self.qz0_net(ctx[0]).chunk(chunks=2, dim=1)\n",
    "        z0 = qz0_mean + qz0_logstd.exp() * torch.randn_like(qz0_mean)\n",
    "\n",
    "        if adjoint:\n",
    "            # Must use the argument `adjoint_params`, since `ctx` is not part of the input to `f`, `g`, and `h`.\n",
    "            adjoint_params = (\n",
    "                    (ctx,) +\n",
    "                    tuple(self.f_net.parameters()) + tuple(self.g_nets.parameters()) + tuple(self.h_net.parameters())\n",
    "            )\n",
    "            zs, log_ratio = torchsde.sdeint_adjoint(\n",
    "                self, z0, ts, adjoint_params=adjoint_params, dt=1e-2, logqp=True, method=method)\n",
    "        else:\n",
    "            zs, log_ratio = torchsde.sdeint(self, z0, ts, dt=1e-2, logqp=True, method=method)\n",
    "\n",
    "        _xs = self.projector(zs)\n",
    "        xs_dist = Normal(loc=_xs, scale=noise_std)\n",
    "        log_pxs = xs_dist.log_prob(xs).sum(dim=(0, 2)).mean(dim=0)\n",
    "\n",
    "        qz0 = torch.distributions.Normal(loc=qz0_mean, scale=qz0_logstd.exp())\n",
    "        pz0 = torch.distributions.Normal(loc=self.pz0_mean, scale=self.pz0_logstd.exp())\n",
    "        logqp0 = torch.distributions.kl_divergence(qz0, pz0).sum(dim=1).mean(dim=0)\n",
    "        logqp_path = log_ratio.sum(dim=0).mean(dim=0)\n",
    "        return log_pxs, logqp0 + logqp_path\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size, ts, bm=None):\n",
    "        eps = torch.randn(size=(batch_size, *self.pz0_mean.shape[1:]), device=self.pz0_mean.device)\n",
    "        z0 = self.pz0_mean + self.pz0_logstd.exp() * eps\n",
    "        zs = torchsde.sdeint(self, z0, ts, names={'drift': 'h'}, dt=1e-3, bm=bm)\n",
    "        # Most of the times in ML, we don't sample the observation noise for visualization purposes.\n",
    "        _xs = self.projector(zs)\n",
    "        return _xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(t0, t1, batch_size, noise_std, train_dir, steps, device, bm = None):\n",
    "    data_path = os.path.join(train_dir, 'lorenz_data.pth')\n",
    "    if os.path.exists(data_path):\n",
    "        data_dict = torch.load(data_path)\n",
    "        xs, ts, _y0 = data_dict['xs'], data_dict['ts'], data_dict['_y0']\n",
    "        logging.warning(f'Loaded toy data at: {data_path}')\n",
    "        if xs.shape[1] != batch_size:\n",
    "            raise ValueError(\"Batch size has changed; please delete and regenerate the data.\")\n",
    "        if ts[0] != t0 or ts[-1] != t1:\n",
    "            raise ValueError(\"Times interval [t0, t1] has changed; please delete and regenerate the data.\")\n",
    "    else:\n",
    "        _y0 = torch.randn(batch_size, 3, device=device)\n",
    "        ts = torch.linspace(t0, t1, steps=steps, device=device)\n",
    "        xs = StochasticLorenz().sample(_y0, ts, noise_std, normalize=True, bm=bm)\n",
    "\n",
    "        os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "        torch.save({'xs': xs, 'ts': ts, '_y0': _y0}, data_path)\n",
    "        logging.warning(f'Stored toy data at: {data_path}')\n",
    "    return xs, ts, _y0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractShorter(xs, t_vae, t1, ts, steps):\n",
    "    threshold = t_vae / t1 * steps\n",
    "    xs_vae = xs[0:int(threshold), :, :]\n",
    "    ts_vae = ts[0:int(threshold)]\n",
    "    return xs_vae, ts_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(xs, ts, xs_full, ts_full, latent_sde, bm_vis, img_path, num_samples=10, long_num_samples = 2):\n",
    "    fig = plt.figure(figsize=(20, 9))\n",
    "    gs = gridspec.GridSpec(1, 4)\n",
    "    ax00 = fig.add_subplot(gs[0, 0], projection='3d')\n",
    "    ax01 = fig.add_subplot(gs[0, 1], projection='3d')\n",
    "    ax02 = fig.add_subplot(gs[0, 2], projection='3d')\n",
    "    ax03 = fig.add_subplot(gs[0, 3], projection='3d')\n",
    "\n",
    "    # Left plot: data.\n",
    "    z1, z2, z3 = np.split(xs.cpu().numpy(), indices_or_sections=3, axis=-1)\n",
    "    [ax00.plot(z1[:, i, 0], z2[:, i, 0], z3[:, i, 0]) for i in range(num_samples)]\n",
    "    ax00.scatter(z1[0, :num_samples, 0], z2[0, :num_samples, 0], z3[0, :10, 0], marker='x')\n",
    "    ax00.set_yticklabels([])\n",
    "    ax00.set_xticklabels([])\n",
    "    ax00.set_zticklabels([])\n",
    "    ax00.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax00.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax00.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax00.set_title('VAE Training Data', fontsize=20)\n",
    "    xlim = ax00.get_xlim()\n",
    "    ylim = ax00.get_ylim()\n",
    "    zlim = ax00.get_zlim()\n",
    "\n",
    "    # Right plot: samples from learned model.\n",
    "    xs = latent_sde.sample(batch_size=xs.size(1), ts=ts, bm=bm_vis).cpu().numpy()\n",
    "    z1, z2, z3 = np.split(xs, indices_or_sections=3, axis=-1)\n",
    "\n",
    "    [ax01.plot(z1[:, i, 0], z2[:, i, 0], z3[:, i, 0]) for i in range(num_samples)]\n",
    "    ax01.scatter(z1[0, :num_samples, 0], z2[0, :num_samples, 0], z3[0, :10, 0], marker='x')\n",
    "    ax01.set_yticklabels([])\n",
    "    ax01.set_xticklabels([])\n",
    "    ax01.set_zticklabels([])\n",
    "    ax01.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax01.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax01.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax01.set_title('Samples from VAE Learned Samples', fontsize=20)\n",
    "    ax01.set_xlim(xlim)\n",
    "    ax01.set_ylim(ylim)\n",
    "    ax01.set_zlim(zlim)\n",
    "\n",
    "    z1_full, z2_full, z3_full = np.split(xs_full.cpu().numpy(), indices_or_sections=3, axis=-1)\n",
    "    [ax02.plot(z1_full[:, i, 0], z2_full[:, i, 0], z3_full[:, i, 0]) for i in range(long_num_samples)]\n",
    "    ax02.scatter(z1_full[0, :long_num_samples, 0], z2_full[0, :long_num_samples, 0], z3_full[0, :long_num_samples, 0], marker='x')\n",
    "    ax02.set_yticklabels([])\n",
    "    ax02.set_xticklabels([])\n",
    "    ax02.set_zticklabels([])\n",
    "    ax02.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax02.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax02.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax02.set_title('Full Training Data', fontsize=20)\n",
    "    ax02.set_xlim(xlim)\n",
    "    ax02.set_ylim(ylim)\n",
    "    ax02.set_zlim(zlim)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        context_full = latent_sde.encoder(torch.flip(xs_full, dims=(0,)))\n",
    "        context_full = torch.flip(context_full, dims=(0,))\n",
    "        latent_sde.contextualize((ts_full, context_full))\n",
    "\n",
    "        qz0_mean, qz0_logstd = latent_sde.qz0_net(context_full[0]).chunk(chunks=2, dim=1)\n",
    "        z0 = qz0_mean + qz0_logstd.exp() * torch.randn_like(qz0_mean)\n",
    "        zs_full, log_ratio = torchsde.sdeint_adjoint(\n",
    "            latent_sde, z0, ts_full, dt=1e-2, logqp=True, method=\"euler\")\n",
    "        _xs_full = latent_sde.projector(zs_full)\n",
    "    \n",
    "    z1_full_pred, z2_full_pred, z3_full_pred = np.split(_xs_full.cpu().numpy(), indices_or_sections=3, axis=-1)\n",
    "    [ax03.plot(z1_full_pred[:, i, 0], z2_full_pred[:, i, 0], z3_full_pred[:, i, 0]) for i in range(long_num_samples)]\n",
    "    ax03.scatter(z1_full_pred[0, :long_num_samples, 0], z2_full_pred[0, :long_num_samples, 0], z3_full_pred[0, :long_num_samples, 0], marker='x')\n",
    "    ax03.set_yticklabels([])\n",
    "    ax03.set_xticklabels([])\n",
    "    ax03.set_zticklabels([])\n",
    "    ax03.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax03.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax03.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax03.set_title('Full Training Data Predicted', fontsize=20)\n",
    "    ax03.set_xlim(xlim)\n",
    "    ax03.set_ylim(ylim)\n",
    "    ax03.set_zlim(zlim)\n",
    "\n",
    "    plt.savefig(img_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024\n",
    "latent_size=4\n",
    "context_size=64\n",
    "hidden_size=128\n",
    "lr_init=1e-2\n",
    "t0=0.\n",
    "t1=10.\n",
    "steps = 500\n",
    "lr_gamma=0.997\n",
    "kl_anneal_iters=1000\n",
    "pause_every=50\n",
    "noise_std=0.01\n",
    "adjoint=False\n",
    "train_dir='./lorenz_63_withMSE/'\n",
    "method=\"euler\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Stored toy data at: ./lorenz_63_withMSE/lorenz_data.pth\n"
     ]
    }
   ],
   "source": [
    "xs_full, ts_full= make_dataset(t0=t0, t1=t1, batch_size=batch_size, noise_std=noise_std, \n",
    "                      train_dir=train_dir, steps = steps, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Madison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
