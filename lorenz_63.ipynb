{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Sequence\n",
    "\n",
    "import fire\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import torchsde\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1, iters)\n",
    "        self._val = maxval / self._iters\n",
    "        self._maxval = maxval\n",
    "\n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val + self._maxval / self._iters)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticLorenz(object):\n",
    "    \"\"\"Stochastic Lorenz attractor.\n",
    "\n",
    "    Used for simulating ground truth and obtaining noisy data.\n",
    "    Details described in Section 7.2 https://arxiv.org/pdf/2001.01328.pdf\n",
    "    Default a, b from https://openreview.net/pdf?id=HkzRQhR9YX\n",
    "    \"\"\"\n",
    "    noise_type = \"diagonal\"\n",
    "    sde_type = \"ito\"\n",
    "\n",
    "    # b: Sequence = (.1, .28, .3)\n",
    "    def __init__(self, a: Sequence = (10., 28., 8 / 3), b: Sequence = (.1, .28, .3)):\n",
    "        super(StochasticLorenz, self).__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def f(self, t, y):\n",
    "        x1, x2, x3 = torch.split(y, split_size_or_sections=(1, 1, 1), dim=1)\n",
    "        a1, a2, a3 = self.a\n",
    "\n",
    "        f1 = a1 * (x2 - x1)\n",
    "        f2 = a2 * x1 - x2 - x1 * x3\n",
    "        f3 = x1 * x2 - a3 * x3\n",
    "        return torch.cat([f1, f2, f3], dim=1)\n",
    "\n",
    "    def g(self, t, y):\n",
    "        x1, x2, x3 = torch.split(y, split_size_or_sections=(1, 1, 1), dim=1)\n",
    "        b1, b2, b3 = self.b\n",
    "\n",
    "        g1 = x1 * b1\n",
    "        g2 = x2 * b2\n",
    "        g3 = x3 * b3\n",
    "        return torch.cat([g1, g2, g3], dim=1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, x0, ts, noise_std, normalize):\n",
    "        \"\"\"Sample data for training. Store data normalization constants if necessary.\"\"\"\n",
    "        xs = torchsde.sdeint(self, x0, ts)\n",
    "        if normalize:\n",
    "            mean, std = torch.mean(xs, dim=(0, 1)), torch.std(xs, dim=(0, 1))\n",
    "            xs.sub_(mean).div_(std).add_(torch.randn_like(xs) * noise_std)\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(t0, t1, batch_size, noise_std, train_dir, steps, device):\n",
    "    data_path = os.path.join(train_dir, 'lorenz_data.pth')\n",
    "    if os.path.exists(data_path):\n",
    "        data_dict = torch.load(data_path)\n",
    "        xs, ts = data_dict['xs'], data_dict['ts']\n",
    "        logging.warning(f'Loaded toy data at: {data_path}')\n",
    "        if xs.shape[1] != batch_size:\n",
    "            raise ValueError(\"Batch size has changed; please delete and regenerate the data.\")\n",
    "        if ts[0] != t0 or ts[-1] != t1:\n",
    "            raise ValueError(\"Times interval [t0, t1] has changed; please delete and regenerate the data.\")\n",
    "    else:\n",
    "        _y0 = torch.randn(batch_size, 3, device=device)\n",
    "        ts = torch.linspace(t0, t1, steps=steps, device=device)\n",
    "        xs = StochasticLorenz().sample(_y0, ts, noise_std, normalize=True)\n",
    "\n",
    "        os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "        torch.save({'xs': xs, 'ts': ts, '_y0': _y0}, data_path)\n",
    "        logging.warning(f'Stored toy data at: {data_path}')\n",
    "    return xs, ts, _y0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out, _ = self.gru(inp)\n",
    "        out = self.lin(out)\n",
    "        return out\n",
    "    \n",
    "class LatentSDE(nn.Module):\n",
    "    sde_type = \"ito\"\n",
    "    noise_type = \"diagonal\"\n",
    "\n",
    "    def __init__(self, data_size, latent_size, context_size, hidden_size):\n",
    "        super(LatentSDE, self).__init__()\n",
    "        # Encoder.\n",
    "        self.encoder = Encoder(input_size=data_size, hidden_size=hidden_size, output_size=context_size)\n",
    "        self.qz0_net = nn.Linear(context_size, latent_size + latent_size)\n",
    "\n",
    "        # Decoder.\n",
    "        self.f_net = nn.Sequential(\n",
    "            nn.Linear(latent_size + context_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "        self.h_net = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "        )\n",
    "        # This needs to be an element-wise function for the SDE to satisfy diagonal noise.\n",
    "        self.g_nets = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(1, hidden_size),\n",
    "                    nn.Softplus(),\n",
    "                    nn.Linear(hidden_size, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "                for _ in range(latent_size)\n",
    "            ]\n",
    "        )\n",
    "        self.projector = nn.Linear(latent_size, data_size)\n",
    "\n",
    "        self.pz0_mean = nn.Parameter(torch.zeros(1, latent_size))\n",
    "        self.pz0_logstd = nn.Parameter(torch.zeros(1, latent_size))\n",
    "\n",
    "        self._ctx = None\n",
    "\n",
    "    def contextualize(self, ctx):\n",
    "        self._ctx = ctx  # A tuple of tensors of sizes (T,), (T, batch_size, d).\n",
    "\n",
    "    def f(self, t, y):\n",
    "        ts, ctx = self._ctx\n",
    "        i = min(torch.searchsorted(ts, t, right=True), len(ts) - 1)\n",
    "        return self.f_net(torch.cat((y, ctx[i]), dim=1))\n",
    "\n",
    "    def h(self, t, y):\n",
    "        return self.h_net(y)\n",
    "\n",
    "    def g(self, t, y):  # Diagonal diffusion.\n",
    "        y = torch.split(y, split_size_or_sections=1, dim=1)\n",
    "        out = [g_net_i(y_i) for (g_net_i, y_i) in zip(self.g_nets, y)]\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "    def forward(self, xs, ts, noise_std, adjoint=False, method=\"euler\"):\n",
    "        # Contextualization is only needed for posterior inference.\n",
    "        ctx = self.encoder(torch.flip(xs, dims=(0,)))\n",
    "        ctx = torch.flip(ctx, dims=(0,))\n",
    "        self.contextualize((ts, ctx))\n",
    "\n",
    "        qz0_mean, qz0_logstd = self.qz0_net(ctx[0]).chunk(chunks=2, dim=1)\n",
    "        z0 = qz0_mean + qz0_logstd.exp() * torch.randn_like(qz0_mean)\n",
    "\n",
    "        if adjoint:\n",
    "            # Must use the argument `adjoint_params`, since `ctx` is not part of the input to `f`, `g`, and `h`.\n",
    "            adjoint_params = (\n",
    "                    (ctx,) +\n",
    "                    tuple(self.f_net.parameters()) + tuple(self.g_nets.parameters()) + tuple(self.h_net.parameters())\n",
    "            )\n",
    "            zs, log_ratio = torchsde.sdeint_adjoint(\n",
    "                self, z0, ts, adjoint_params=adjoint_params, dt=1e-2, logqp=True, method=method)\n",
    "        else:\n",
    "            zs, log_ratio = torchsde.sdeint(self, z0, ts, dt=1e-2, logqp=True, method=method)\n",
    "\n",
    "        _xs = self.projector(zs)\n",
    "        xs_dist = Normal(loc=_xs, scale=noise_std)\n",
    "        log_pxs = xs_dist.log_prob(xs).sum(dim=(0, 2)).mean(dim=0)\n",
    "\n",
    "        qz0 = torch.distributions.Normal(loc=qz0_mean, scale=qz0_logstd.exp())\n",
    "        pz0 = torch.distributions.Normal(loc=self.pz0_mean, scale=self.pz0_logstd.exp())\n",
    "        logqp0 = torch.distributions.kl_divergence(qz0, pz0).sum(dim=1).mean(dim=0)\n",
    "        logqp_path = log_ratio.sum(dim=0).mean(dim=0)\n",
    "        return log_pxs, logqp0 + logqp_path\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size, ts, bm=None):\n",
    "        eps = torch.randn(size=(batch_size, *self.pz0_mean.shape[1:]), device=self.pz0_mean.device)\n",
    "        z0 = self.pz0_mean + self.pz0_logstd.exp() * eps\n",
    "        zs = torchsde.sdeint(self, z0, ts, names={'drift': 'h'}, dt=1e-3, bm=bm)\n",
    "        # Most of the times in ML, we don't sample the observation noise for visualization purposes.\n",
    "        _xs = self.projector(zs)\n",
    "        return _xs, z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(xs, ts, latent_sde, bm_vis, img_path, num_samples=10, method = \"euler\"):\n",
    "    fig = plt.figure(figsize=(20, 9))\n",
    "    gs = gridspec.GridSpec(1, 2, fig)\n",
    "\n",
    "    # Left plot: data.\n",
    "    ax00 = plt.subplot(gs[0, 0], projection='3d')\n",
    "    z1, z2, z3 = np.split(xs.cpu().numpy(), indices_or_sections=3, axis=-1)\n",
    "    [ax00.plot(z1[:, i, 0], z2[:, i, 0], z3[:, i, 0]) for i in range(num_samples)]\n",
    "    ax00.scatter(z1[0, :num_samples, 0], z2[0, :num_samples, 0], z3[0, :num_samples, 0], marker='x')\n",
    "    ax00.set_yticklabels([])\n",
    "    ax00.set_xticklabels([])\n",
    "    ax00.set_zticklabels([])\n",
    "    ax00.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax00.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax00.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax00.set_title('Data', fontsize=20)\n",
    "    xlim = ax00.get_xlim()\n",
    "    ylim = ax00.get_ylim()\n",
    "    zlim = ax00.get_zlim()\n",
    "\n",
    "    # Right plot: samples from learned model.\n",
    "    generated_xs,  = latent_sde.sample(batch_size=xs.size(1), ts=ts, bm=bm_vis).cpu().numpy()\n",
    "    z1, z2, z3 = np.split(generated_xs, indices_or_sections=3, axis=-1)\n",
    "    ax01 = plt.subplot(gs[0, 1], projection='3d')\n",
    "    [ax01.plot(z1[:, i, 0], z2[:, i, 0], z3[:, i, 0]) for i in range(num_samples)]\n",
    "    ax01.scatter(z1[0, :num_samples, 0], z2[0, :num_samples, 0], z3[0, :num_samples, 0], marker='x')\n",
    "    ax01.set_yticklabels([])\n",
    "    ax01.set_xticklabels([])\n",
    "    ax01.set_zticklabels([])\n",
    "    ax01.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax01.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax01.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax01.set_title('Samples', fontsize=20)\n",
    "    ax01.set_xlim(xlim)\n",
    "    ax01.set_ylim(ylim)\n",
    "    ax01.set_zlim(zlim)   \n",
    "\n",
    "    plt.savefig(img_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visXYZ(xs, ts, latent_sde, bm_vis, img_path, num_samples=10, method = \"euler\"):\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 12))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuralSDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
